{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c18ba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/i574473/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "from sklearn.metrics import classification_report\n",
    "from itertools import islice, chain\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "from IPython.display import Image\n",
    "import random\n",
    "import zipfile\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "import spacy\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from sklearn import utils\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f2fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bbc-news-data.csv')\n",
    "\n",
    "bbc_train, bbc_test = train_test_split(df, test_size=0.2, random_state=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b46a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>sport</td>\n",
       "      <td>116.txt</td>\n",
       "      <td>Bosvelt optimistic over new deal</td>\n",
       "      <td>Manchester City's Paul Bosvelt will find out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>politics</td>\n",
       "      <td>184.txt</td>\n",
       "      <td>Blair rejects Iraq advice calls</td>\n",
       "      <td>Tony Blair has rejected calls for the publica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>sport</td>\n",
       "      <td>305.txt</td>\n",
       "      <td>Kirwan demands Italy consistency</td>\n",
       "      <td>Italy coach John Kirwan has challenged his si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>tech</td>\n",
       "      <td>034.txt</td>\n",
       "      <td>UK gets official virus alert site</td>\n",
       "      <td>A rapid alerting service that tells home comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>sport</td>\n",
       "      <td>141.txt</td>\n",
       "      <td>Benitez issues warning to Gerrard</td>\n",
       "      <td>Liverpool manager Rafael Benitez has ordered ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category filename                              title  \\\n",
       "1428     sport  116.txt   Bosvelt optimistic over new deal   \n",
       "1079  politics  184.txt    Blair rejects Iraq advice calls   \n",
       "1617     sport  305.txt   Kirwan demands Italy consistency   \n",
       "1857      tech  034.txt  UK gets official virus alert site   \n",
       "1453     sport  141.txt  Benitez issues warning to Gerrard   \n",
       "\n",
       "                                                content  \n",
       "1428   Manchester City's Paul Bosvelt will find out ...  \n",
       "1079   Tony Blair has rejected calls for the publica...  \n",
       "1617   Italy coach John Kirwan has challenged his si...  \n",
       "1857   A rapid alerting service that tells home comp...  \n",
       "1453   Liverpool manager Rafael Benitez has ordered ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20ffbede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sport            413\n",
      "business         406\n",
      "politics         340\n",
      "tech             314\n",
      "entertainment    307\n",
      "Name: category, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic = bbc_train['category'].value_counts()\n",
    "print(topic)\n",
    "plt.figure(figsize=(12,4))\n",
    "# sns.barplot(data=df, x=\"island\", y=\"body_mass_g\")\n",
    "sns.barplot(topic.index, topic.values, alpha=0.8)\n",
    "# plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "# plt.xlabel('Topic', fontsize=12)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a1dec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando dados de treinamento...\n",
      "\n",
      "\tConcluída a leitura de dados para o tópico:  Ad sales boost Time Warner profit\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m test_data\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessando dados de treinamento...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m words, train_words \u001b[38;5;241m=\u001b[39m \u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbc_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProcessando dados de teste...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m test_words \u001b[38;5;241m=\u001b[39m read_test_data(bbc_test)\n",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m, in \u001b[0;36mread_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      8\u001b[0m train_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(filename\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 10\u001b[0m     text_string \u001b[38;5;241m=\u001b[39m \u001b[43mfilename\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m     text_string \u001b[38;5;241m=\u001b[39m text_string\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     12\u001b[0m     text_string \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(text_string)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "      Extrai artigos até um determinado limite em um arquivo zip como uma lista de palavras\n",
    "      e pré-processa usando a biblioteca nltk python\n",
    "      \"\"\"\n",
    "        \n",
    "    data = [[],[]]\n",
    "    train_data = {}\n",
    "    for i in range(filename.shape[0]):\n",
    "        text_string = filename[filename.columns[1]][i]\n",
    "        text_string = text_string.lower()\n",
    "        text_string = nltk.word_tokenize(text_string)\n",
    "        # Atribui a classe aos arquivos\n",
    "        data[0].append(text_string)\n",
    "        data[1].append(filename[filename.columns[2]][i])\n",
    "        \"\"\" Atribui o tópico ao documento \"\"\"\n",
    "        train_data[filename[filename.columns[2]][i]+'-'+filename[filename.columns[0]][i]] = text_string\n",
    "        print('\\tConcluída a leitura de dados para o tópico: ',filename[filename.columns[2]][i]) \n",
    "               \n",
    "    return data, train_data\n",
    "\n",
    "def read_test_data(filename):\n",
    "    \"\"\"\n",
    "      Extrai artigos até um determinado limite em um arquivo zip como uma lista de palavras\n",
    "      e pré-processa usando a biblioteca nltk python\n",
    "      \"\"\"\n",
    "        \n",
    "    test_data = {}\n",
    "    for i in range(filename.shape[0]):\n",
    "        text_string = filename[filename.columns[1]][i]\n",
    "        text_string = text_string.lower()\n",
    "        text_string = nltk.word_tokenize(text_string)\n",
    "        # Atribui a classe aos arquivos\n",
    "        \"\"\" Atribui o tópico ao documento \"\"\"\n",
    "        test_data[filename[filename.columns[0]][i].astype(str)] = text_string\n",
    "        print('\\tConcluída a leitura de dados para o tópico: ',filename[filename.columns[0]][i]) \n",
    "               \n",
    "    return test_data\n",
    "\n",
    "print('Processando dados de treinamento...\\n')\n",
    "words, train_words = read_data(bbc_train)\n",
    "\n",
    "print('\\nProcessando dados de teste...\\n')\n",
    "\n",
    "test_words = read_test_data(bbc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f920a800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
